{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ab1ad2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Python의 Model I/O 에 대해 학습함\n",
    "\n",
    "FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ee38e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/4cv0q0kj0bq39hdg5q154dbw0000gn/T/ipykernel_18379/1151379228.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8e978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854d99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db83e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know this:\n",
      "- Capital: Madrid\n",
      "- Language: Spanish\n",
      "- Food: Tapas and Paella\n",
      "- Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I know this:\\n- Capital: Madrid\\n- Language: Spanish\\n- Food: Tapas and Paella\\n- Currency: Euro', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--7fcb8751-60ac-4dab-9f56-c56496641149-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\" : \"Spain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de15ce2",
   "metadata": {},
   "source": [
    "# FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ee7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",         # Specifies the OpenAI model\n",
    "    temperature=0.1,             # Low randomness; more deterministic responses\n",
    "    streaming=True,              # Enables streaming responses token-by-token\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()  # Streams output to standard output\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"what do you know about {country}?\"),\n",
    "        (\"ai\", \"{answer}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"what do you know abiut {country}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28f17fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korea refers to two countries: \n",
      "\n",
      "1. **South Korea** (Republic of Korea)\n",
      "   - Capital: Seoul\n",
      "   - Language: Korean\n",
      "   - Currency: South Korean Won (KRW)\n",
      "\n",
      "2. **North Korea** (Democratic People's Republic of Korea)\n",
      "   - Capital: Pyongyang\n",
      "   - Language: Korean\n",
      "   - Currency: North Korean Won (KPW)\n",
      "\n",
      "Both countries share a common cultural and historical background but have distinct political systems."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Korea refers to two countries: \\n\\n1. **South Korea** (Republic of Korea)\\n   - Capital: Seoul\\n   - Language: Korean\\n   - Currency: South Korean Won (KRW)\\n\\n2. **North Korea** (Democratic People's Republic of Korea)\\n   - Capital: Pyongyang\\n   - Language: Korean\\n   - Currency: North Korean Won (KPW)\\n\\nBoth countries share a common cultural and historical background but have distinct political systems.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--9c9edb66-77db-4be1-85fe-95c42516f5c1-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain: any= final_prompt | chat\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"country\", \"korea\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b51c0",
   "metadata": {},
   "source": [
    "# LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1308317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0738d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomExampleSelecter(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples: Any = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f7f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "example_selector: RandomExampleSelecter = RandomExampleSelecter(\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc223f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Italy?\\nAI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Human: What do you know about {counrty}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "prompt.format(counrty=\"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c1e87",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463d264",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PipelinePromptTemplate\n\u001b[32m      6\u001b[39m chat: Any = ChatOpenAI(\n\u001b[32m      7\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     temperature=\u001b[32m0.1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ]\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.prompt'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompt import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat: Any = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",         # Specifies the OpenAI model\n",
    "    temperature=0.1,             # Low randomness; more deterministic responses\n",
    "    streaming=True,              # Enables streaming responses token-by-token\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()  # Streams output to standard output\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro: promptTemplate = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant\n",
    "    And you are impersomating a {character}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "example: promptTemplate = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    this is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "start: promptTemplate = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    start now:\n",
    "    \n",
    "    Human: {question}\n",
    "    you:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "final: Prompttemplate = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "\n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt: list[tuple[str, PromptTempl... ]] = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start)\n",
    "]\n",
    "\n",
    "full_prompt = pipelinePromptTemplate(\n",
    "    final_prompt = final,\n",
    "    pipeline_primpts = prompts\n",
    ")\n",
    "\n",
    "chain: Any = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-7day",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
