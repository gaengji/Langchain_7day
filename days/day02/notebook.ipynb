{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ab1ad2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Python의 Model I/O 에 대해 학습함\n",
    "\n",
    "FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\" : \"Spain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de15ce2",
   "metadata": {},
   "source": [
    "# FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"what do you know about {country}?\"),\n",
    "        (\"ai\", \"{answer}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"what do you know abiut {country}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain: any= final_prompt | chat\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"country\", \"korea\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b51c0",
   "metadata": {},
   "source": [
    "# RandomBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1308317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0738d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomExampleSelecter(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples: Any = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "example_sele = RandomExampleSelecter(\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc223f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Human: What do you know about {counrty}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "prompt.format(counrty=\"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c1e87",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.1,\n",
    "  streaming=True,\n",
    "  callbacks=[\n",
    "    StreamingStdOutCallbackHandler(),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  You are a role playing assistant.\n",
    "  And you are impersonating a {character}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  this is an example of how you talk:\n",
    "\n",
    "  Human: {example_question}\n",
    "  You: {example_answer}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "start= PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  Strat now!\n",
    "\n",
    "  Human: {question}\n",
    "  You:\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "  \"\"\"\n",
    "  {intro}\n",
    "\n",
    "  {example}\n",
    "\n",
    "  {start}\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "  (\"intro\", intro),\n",
    "  (\"example\", example),\n",
    "  (\"start\", start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "  final_prompt=final,\n",
    "  pipeline_prompts=prompts\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bfae0",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56d6f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "\n",
    "# prompt.format(country=\"Germmany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2abddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Germany is Berlin.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CKg6F1zUX4gx831W8cJf2aDgZQ4u3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--305f16fe-12f4-429d-9658-949d50c5cf7c-0', usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Germmany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2008b",
   "metadata": {},
   "source": [
    "# LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138a785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/4cv0q0kj0bq39hdg5q154dbw0000gn/T/ipykernel_66685/1671577656.py:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d03405",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt: PromptTemplate = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa74c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "# prompt.format(counrty=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aebc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain is a country located in southwestern Europe on the Iberian Peninsula. Its capital city is Madrid. The official language is Spanish (Castilian), and the country is known for its rich cultural heritage, including flamenco music and dance, festivals like La Tomatina and Running of the Bulls, and historic sites such as the Alhambra in Granada and Sagrada Família in Barcelona. Spain's cuisine features dishes like paella, tapas, and churros. The currency used is the Euro (€). Spain is also famous for its diverse landscapes, from beaches along the Mediterranean and Atlantic coasts to mountainous regions like the Pyrenees and Sierra Nevada."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Spain is a country located in southwestern Europe on the Iberian Peninsula. Its capital city is Madrid. The official language is Spanish (Castilian), and the country is known for its rich cultural heritage, including flamenco music and dance, festivals like La Tomatina and Running of the Bulls, and historic sites such as the Alhambra in Granada and Sagrada Família in Barcelona. Spain's cuisine features dishes like paella, tapas, and churros. The currency used is the Euro (€). Spain is also famous for its diverse landscapes, from beaches along the Mediterranean and Atlantic coasts to mountainous regions like the Pyrenees and Sierra Nevada.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--a9d65192-2983-4b33-89b9-e519924e5523-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"spain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b96755",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9d2599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the capital of Japan\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [4ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The capital of Japan is Tokyo.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The capital of Japan is Tokyo.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 13,\n",
      "                \"total_tokens\": 20,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_51db84afab\",\n",
      "              \"id\": \"chatcmpl-CKgHYs5pIqmjGnjidEsL615fpCQnr\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--593acced-94c6-41f2-8d56-63cc859d6a1e-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 13,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 20,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              },\n",
      "              \"total_cost\": 0\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache())\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "set_debug(True)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "chat.predict(\"What is the capital of Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1205d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"What is the capital of Japan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da2ad0",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0aaa808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1268\n",
      "\tPrompt Tokens: 29\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 1239\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0007477499999999999\n",
      "0.0007477499999999999\n",
      "1268\n",
      "29\n",
      "1239\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.globals import set_debug\n",
    "from typing import Any\n",
    "\n",
    "set_debug(False)\n",
    "\n",
    "chat: Any = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a: Any = chat.predict(\"What is a Recipt for KFC\")\n",
    "    b: Any = chat.predict(\"What is a Recipt for Sushi\")\n",
    "    \n",
    "    print(usage)\n",
    "    print(usage.total_cost) # 전체 비용\n",
    "    print(usage.total_tokens) # 토큰 총합\n",
    "    print(usage.prompt_tokens) # 프롬프트에 사용된 토큰수\n",
    "    print(usage.completion_tokens) # 모델이 쓴 토큰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-7day",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
